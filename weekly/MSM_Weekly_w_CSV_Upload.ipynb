{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The purpose of this is to be able to compare the volatility regimes with the existing portfolio framework\n",
    "#To utilize this, simple run whatever model you want, then upload the vol into the vol_regime.xlsx spreadsheet\n",
    "#Instead of doing it's own MSM, the model will pull the volatility regime from the excel file and then apply all the logic going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NicholasRatti\\AppData\\Local\\Temp\\ipykernel_47776\\1952905365.py:537: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(periods_per_year)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Statistics:\n",
      "        Statistic       Strategy         Market\n",
      "             CAGR 11.6246247249% 11.6246247249%\n",
      "     Max Drawdown        -29.18%        -29.18%\n",
      "     Sharpe Ratio           0.58           0.58\n",
      "    Sortino Ratio           0.85           0.85\n",
      "Information Ratio            NaN            NaN\n",
      "    Exposure >= 1        100.00%            NaN\n",
      "Output table:\n",
      "                    Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2015-01-01  2058.899902  2072.360107  1992.439941  2025.900024  2025.900024   \n",
      "2015-01-08  2030.609985  2064.429932  1988.439941  2011.270020  2011.270020   \n",
      "2015-01-15  2013.750000  2038.290039  1988.119995  2032.119995  2032.119995   \n",
      "2015-01-22  2034.300049  2064.620117  2001.489990  2002.160034  2002.160034   \n",
      "2015-01-29  2002.449951  2054.739990  1980.900024  2041.510010  2041.510010   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2024-10-10  5778.359863  5871.410156  5764.759766  5842.470215  5842.470215   \n",
      "2024-10-17  5875.620117  5878.459961  5762.410156  5797.419922  5797.419922   \n",
      "2024-10-24  5817.799805  5862.819824  5784.919922  5813.669922  5813.669922   \n",
      "2024-10-31  5775.339844  5936.140137  5696.509766  5929.040039  5929.040039   \n",
      "2024-11-07  5947.209961  6017.310059  5947.209961  5985.379883  5985.379883   \n",
      "\n",
      "                 Volume     Syn_Open  Adjusted_Open  FEDFUNDS  DGS10  ...  \\\n",
      "Date                                                                  ...   \n",
      "2015-01-01  14773410000  2058.899902    2058.899902      0.11    NaN  ...   \n",
      "2015-01-08  19240590000  2030.609985    2030.609985      0.11   2.03  ...   \n",
      "2015-01-15  16007540000  2013.750000    2013.750000      0.11   1.77  ...   \n",
      "2015-01-22  18612710000  2034.300049    2034.300049      0.11   1.90  ...   \n",
      "2015-01-29  21461940000  2002.449951    2002.449951      0.11   1.77  ...   \n",
      "...                 ...          ...            ...       ...    ...  ...   \n",
      "2024-10-10  16772110000  5778.359863    5778.359863       NaN   4.09  ...   \n",
      "2024-10-17  17136240000  5875.620117    5875.620117       NaN   4.09  ...   \n",
      "2024-10-24  18465810000  5817.799805    5817.799805       NaN   4.21  ...   \n",
      "2024-10-31  21922010000  5775.339844    5775.339844       NaN   4.28  ...   \n",
      "2024-11-07  22389060000  5947.209961    5947.209961       NaN   4.31  ...   \n",
      "\n",
      "            Last_Buy_Value  Last_Buy_Date  Profit/Loss  Tax  Tax_Amount  \\\n",
      "Date                                                                      \n",
      "2015-01-01            None            NaT            0    0           0   \n",
      "2015-01-08            None            NaT            0    0           0   \n",
      "2015-01-15            None            NaT            0    0           0   \n",
      "2015-01-22            None            NaT            0    0           0   \n",
      "2015-01-29            None            NaT            0    0           0   \n",
      "...                    ...            ...          ...  ...         ...   \n",
      "2024-10-10            None            NaT            0    0           0   \n",
      "2024-10-17            None            NaT            0    0           0   \n",
      "2024-10-24            None            NaT            0    0           0   \n",
      "2024-10-31            None            NaT            0    0           0   \n",
      "2024-11-07            None            NaT            0    0           0   \n",
      "\n",
      "            Ending_Portfolio_Value  Index_Drawdown Strategy_Drawdown  \\\n",
      "Date                                                                   \n",
      "2015-01-01           100000.000000        0.000000          0.000000   \n",
      "2015-01-08            99277.851587       -0.007221         -0.007221   \n",
      "2015-01-15           100307.022589        0.000000          0.000000   \n",
      "2015-01-22            98828.175628       -0.014743         -0.014743   \n",
      "2015-01-29           100770.521011        0.000000          0.000000   \n",
      "...                            ...             ...               ...   \n",
      "2024-10-10           288388.871338        0.000000          0.000000   \n",
      "2024-10-17           286165.153858       -0.007711         -0.007711   \n",
      "2024-10-24           286967.266490       -0.004929         -0.004929   \n",
      "2024-10-31           292662.025155        0.000000          0.000000   \n",
      "2024-11-07           295443.003637        0.000000          0.000000   \n",
      "\n",
      "           Portfolio_Value   Market_Value  \n",
      "Date                                       \n",
      "2015-01-01   100000.000000  100000.000000  \n",
      "2015-01-08    99277.851587   99277.851587  \n",
      "2015-01-15   100307.022589  100307.022589  \n",
      "2015-01-22    98828.175628   98828.175628  \n",
      "2015-01-29   100770.521011  100770.521011  \n",
      "...                    ...            ...  \n",
      "2024-10-10   288388.871338  288388.871338  \n",
      "2024-10-17   286165.153858  286165.153858  \n",
      "2024-10-24   286967.266490  286967.266490  \n",
      "2024-10-31   292662.025155  292662.025155  \n",
      "2024-11-07   295443.003637  295443.003637  \n",
      "\n",
      "[515 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NicholasRatti\\AppData\\Local\\Temp\\ipykernel_47776\\1952905365.py:764: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'Regime_Change'] = data['Market_Regime'] != data['Market_Regime'].shift()\n",
      "C:\\Users\\NicholasRatti\\AppData\\Local\\Temp\\ipykernel_47776\\1952905365.py:765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'Regime_ID'] = data['Regime_Change'].cumsum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regime Length Statistics:\n",
      " count      1.0\n",
      "mean     515.0\n",
      "std        NaN\n",
      "min      515.0\n",
      "25%      515.0\n",
      "50%      515.0\n",
      "75%      515.0\n",
      "max      515.0\n",
      "dtype: float64\n",
      "\n",
      "Returns Statistics by Market Regime:\n",
      "                Mean Daily Return  Daily Standard Deviation  Number of Days  \\\n",
      "Market_Regime                                                                \n",
      "Unknown                 0.235358                   2.21087             515   \n",
      "\n",
      "               Mean Regime Length  \n",
      "Market_Regime                      \n",
      "Unknown                       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NicholasRatti\\AppData\\Local\\Temp\\ipykernel_47776\\1952905365.py:840: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'Market_3yr_CAGR'] = rolling_3yr_cagr(data['Market_Value'])\n",
      "C:\\Users\\NicholasRatti\\AppData\\Local\\Temp\\ipykernel_47776\\1952905365.py:841: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'Strategy_3yr_CAGR'] = rolling_3yr_cagr(data['Portfolio_Value'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worst 3-Year Periods for Each Decade (Market Downturns):\n",
      "           Start_Date   End_Date  Market_3yr_CAGR  Strategy_3yr_CAGR  \\\n",
      "Date                                                                   \n",
      "2015-01-01 2015-01-01 2015-01-01              NaN                NaN   \n",
      "2020-01-02 2017-01-05 2020-01-02              NaN                NaN   \n",
      "\n",
      "            Start_Strategy_Value  End_Strategy_Value  Start_Market_Value  \\\n",
      "Date                                                                       \n",
      "2015-01-01         100000.000000       100000.000000       100000.000000   \n",
      "2020-01-02         112311.567251       160573.079107       112311.567251   \n",
      "\n",
      "            End_Market_Value  \n",
      "Date                          \n",
      "2015-01-01     100000.000000  \n",
      "2020-01-02     160573.079107  \n",
      "\n",
      "Performance Statistics:\n",
      "        Statistic       Strategy         Market\n",
      "             CAGR 11.6246247249% 11.6246247249%\n",
      "     Max Drawdown        -29.18%        -29.18%\n",
      "     Sharpe Ratio           0.58           0.58\n",
      "    Sortino Ratio           0.85           0.85\n",
      "Information Ratio            NaN            NaN\n",
      "    Exposure >= 1        100.00%            NaN\n",
      "\n",
      "Combined Table:\n",
      "          Date  Portfolio Exposure  Portfolio Leverage Vol_Regime\n",
      "0      Current                 1.0                 0.0    Unknown\n",
      "1   04-18-2024                 1.0                 0.0    Unknown\n",
      "2   04-25-2024                 1.0                 0.0    Unknown\n",
      "3   05-02-2024                 1.0                 0.0    Unknown\n",
      "4   05-09-2024                 1.0                 0.0    Unknown\n",
      "5   05-16-2024                 1.0                 0.0    Unknown\n",
      "6   05-23-2024                 1.0                 0.0    Unknown\n",
      "7   05-30-2024                 1.0                 0.0    Unknown\n",
      "8   06-06-2024                 1.0                 0.0    Unknown\n",
      "9   06-13-2024                 1.0                 0.0    Unknown\n",
      "10  06-20-2024                 1.0                 0.0    Unknown\n",
      "11  06-27-2024                 1.0                 0.0    Unknown\n",
      "12  07-04-2024                 1.0                 0.0    Unknown\n",
      "13  07-11-2024                 1.0                 0.0    Unknown\n",
      "14  07-18-2024                 1.0                 0.0    Unknown\n",
      "15  07-25-2024                 1.0                 0.0    Unknown\n",
      "16  08-01-2024                 1.0                 0.0    Unknown\n",
      "17  08-08-2024                 1.0                 0.0    Unknown\n",
      "18  08-15-2024                 1.0                 0.0    Unknown\n",
      "19  08-22-2024                 1.0                 0.0    Unknown\n",
      "20  08-29-2024                 1.0                 0.0    Unknown\n",
      "21  09-05-2024                 1.0                 0.0    Unknown\n",
      "22  09-12-2024                 1.0                 0.0    Unknown\n",
      "23  09-19-2024                 1.0                 0.0    Unknown\n",
      "24  09-26-2024                 1.0                 0.0    Unknown\n",
      "25  10-03-2024                 1.0                 0.0    Unknown\n",
      "26  10-10-2024                 1.0                 0.0    Unknown\n",
      "27  10-17-2024                 1.0                 0.0    Unknown\n",
      "28  10-24-2024                 1.0                 0.0    Unknown\n",
      "29  10-31-2024                 1.0                 0.0    Unknown\n",
      "30  11-07-2024                 1.0                 0.0    Unknown\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from fredapi import Fred\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import gridspec\n",
    "import pyfolio as pf\n",
    "import empyrical as ep\n",
    "from decimal import Decimal\n",
    "\n",
    "def main():\n",
    "    # Set up your FRED API key\n",
    "    fred_api_key = 'bf9400b3f6a177d421bda60a77384789'  # Replace with your FRED API key\n",
    "    fred = Fred(api_key=fred_api_key)\n",
    "    \n",
    "    # Define ticker and date range\n",
    "    ticker = \"^GSPC\"\n",
    "    edited_ticker = ticker.replace(\"^\", \"\")\n",
    "    start_date = \"1950-01-01\"\n",
    "    end_date = (get_previous_trading_day() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Fetch market data\n",
    "    market_data = fetch_market_data(ticker, start_date, end_date)\n",
    "    \n",
    "    # Fetch FRED data\n",
    "    fred_data = fetch_fred_data(start_date, end_date, fred)\n",
    "    \n",
    "    # Process data\n",
    "    data = process_data(market_data, fred_data)\n",
    "    \n",
    "    # Read Vol_Regime from Excel file\n",
    "    data = read_vol_regime_from_excel(data)\n",
    "    \n",
    "    # Define market regimes\n",
    "    data = define_market_regimes(data)\n",
    "    \n",
    "    # Add Triangular Moving Averages and Indicators\n",
    "    data = add_triangular_moving_averages_and_indicators(data)\n",
    "    \n",
    "    # Calculate exposures\n",
    "    data = calculate_exposures(data)\n",
    "    \n",
    "    # Calculate returns and portfolio values\n",
    "    data = calculate_returns_and_portfolio_values(data)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    stats_df = calculate_performance_metrics(data)\n",
    "    \n",
    "    # Define output paths\n",
    "    output_csv_path = 'output/output_table.csv'\n",
    "    output_pdf_path = 'output/output_report.pdf'\n",
    "    trades_csv_path = 'output/trades_data.csv'\n",
    "    worst_periods_csv_path = 'output/worst_periods.csv'\n",
    "    \n",
    "    # Output results\n",
    "    output_results(\n",
    "        data,\n",
    "        output_csv_path,\n",
    "        output_pdf_path,\n",
    "        trades_csv_path,\n",
    "        worst_periods_csv_path,\n",
    "        stats_df,\n",
    "        edited_ticker,\n",
    "        start_date,\n",
    "        end_date\n",
    "    )\n",
    "    \n",
    "    # Output to SQLite database\n",
    "    output_to_database(data)\n",
    "\n",
    "def get_previous_trading_day():\n",
    "    today = datetime.now().date()\n",
    "    previous_day = today - timedelta(days=1)\n",
    "    \n",
    "    while previous_day.weekday() >= 5:  # 5 = Saturday, 6 = Sunday\n",
    "        previous_day -= timedelta(days=1)\n",
    "    \n",
    "    return previous_day\n",
    "\n",
    "def fetch_market_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval=\"1wk\")\n",
    "    \n",
    "    # Create 'Syn_Open' column\n",
    "    data['Syn_Open'] = data['Open']\n",
    "    mask = (data['Open'] == 0) | (data['Open'].isna())\n",
    "    data.loc[mask, 'Syn_Open'] = data.loc[mask, ['High', 'Low', 'Close']].mean(axis=1)\n",
    "    \n",
    "    # Use 'Syn_Open' where 'Open' is NaN or 0\n",
    "    data['Adjusted_Open'] = data['Syn_Open']\n",
    "    \n",
    "    # Calculate daily returns and set the first day's return to 0\n",
    "    data['Index_Returns'] = data['Adj Close'].pct_change().fillna(0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def fetch_fred_data(start_date, end_date, fred):\n",
    "    ffr_daily = fred.get_series('FEDFUNDS', start_date, end_date)\n",
    "    ffr_10yr = fred.get_series('DGS10', start_date, end_date)\n",
    "    tb3ms = fred.get_series('TB3MS', start_date, end_date)\n",
    "    effr_daily = fred.get_series('EFFR', start_date, end_date)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    ffr_daily = pd.DataFrame(ffr_daily, columns=['FEDFUNDS'])\n",
    "    ffr_10yr = pd.DataFrame(ffr_10yr, columns=['DGS10'])\n",
    "    tb3ms = pd.DataFrame(tb3ms, columns=['TB3MS'])\n",
    "    effr_daily = pd.DataFrame(effr_daily, columns=['EFFR'])\n",
    "    \n",
    "    # Resample to daily frequency and fill missing values\n",
    "    ffr_daily = ffr_daily.resample('D').ffill()\n",
    "    ffr_10yr = ffr_10yr.resample('D').ffill()\n",
    "    tb3ms = tb3ms.resample('D').ffill()\n",
    "    effr_daily = effr_daily.resample('D').ffill()\n",
    "    \n",
    "    fred_data = {\n",
    "        'FEDFUNDS': ffr_daily,\n",
    "        'DGS10': ffr_10yr,\n",
    "        'TB3MS': tb3ms,\n",
    "        'EFFR': effr_daily\n",
    "    }\n",
    "    \n",
    "    return fred_data\n",
    "\n",
    "def process_data(data, fred_data):\n",
    "    # Merge S&P 500 data with Fed Funds Rate data\n",
    "    data = data.join(fred_data['FEDFUNDS'])\n",
    "    data = data.join(fred_data['DGS10'])\n",
    "    data = data.join(fred_data['TB3MS'])\n",
    "    data = data.join(fred_data['EFFR'])\n",
    "    \n",
    "    # Use TB3MS for dates before 1954-07-01, daily rate if available, otherwise use 10-year rate\n",
    "    data['Effective_Fed_Rate'] = np.where(\n",
    "        data.index < '1954-07-01',\n",
    "        data['TB3MS'],\n",
    "        data['FEDFUNDS']\n",
    "    )\n",
    "    data['Effective_Fed_Rate'] = np.where(\n",
    "        data.index >= '2000-07-03',\n",
    "        data['EFFR'],\n",
    "        data['Effective_Fed_Rate']\n",
    "    )\n",
    "    data['Effective_Fed_Rate'] = data['Effective_Fed_Rate'].combine_first(data['DGS10'])\n",
    "    \n",
    "    # Handle NaN values by using the previous day's value\n",
    "    data['Effective_Fed_Rate'] = data['Effective_Fed_Rate'].ffill()\n",
    "    \n",
    "    # Convert Effective Fed Rate to percentage format\n",
    "    data['Effective_Fed_Rate'] = data['Effective_Fed_Rate'] / 100\n",
    "    \n",
    "    # Define IBKR Fee\n",
    "    ibkr_fee = 0.0075  # 0.75% as a decimal\n",
    "    \n",
    "    # Add IBKR Fee as a new column\n",
    "    data['IBKR_Rate'] = ibkr_fee\n",
    "    \n",
    "    # Calculate Daily Leverage Rate\n",
    "    data['Daily_Leverage_Rate'] = (data['Effective_Fed_Rate'] + ibkr_fee) / 52\n",
    "    \n",
    "    return data\n",
    "\n",
    "def read_vol_regime_from_excel(data):\n",
    "    # Read Vol_Regime from vol_regime.xlsx\n",
    "    vol_regime_df = pd.read_excel('vol_regime.xlsx', index_col=0)\n",
    "    vol_regime_df.index = pd.to_datetime(vol_regime_df.index)\n",
    "    \n",
    "    # Ensure the 'Vol_Regime' column exists\n",
    "    if 'Vol_Regime' not in vol_regime_df.columns:\n",
    "        raise ValueError(\"The 'Vol_Regime' column is not found in vol_regime.xlsx\")\n",
    "    \n",
    "    # Merge vol_regime_df into data\n",
    "    data = data.merge(vol_regime_df[['Vol_Regime']], how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def define_market_regimes(data):\n",
    "    # Calculate 250-day triangular moving average\n",
    "    data['250_TMA'] = triangular_moving_average(data['Adj Close'], 37)\n",
    "    \n",
    "    # Define the four market regimes for 250 TMA\n",
    "    conditions = [\n",
    "        (data['Vol_Regime'] == 1) & (data['Adj Close'] < data['250_TMA']),\n",
    "        (data['Vol_Regime'] == 1) & (data['Adj Close'] >= data['250_TMA']),\n",
    "        (data['Vol_Regime'] == 0) & (data['Adj Close'] < data['250_TMA']),\n",
    "        (data['Vol_Regime'] == 0) & (data['Adj Close'] >= data['250_TMA']),\n",
    "    ]\n",
    "    choices = [\n",
    "        'Bearish High Variance',\n",
    "        'Bullish High Variance',\n",
    "        'Bearish Low Variance',\n",
    "        'Bullish Low Variance'\n",
    "    ]\n",
    "    \n",
    "    # Specify a default value that matches the data type of choices\n",
    "    data['Market_Regime'] = np.select(conditions, choices, default='Unknown')\n",
    "    \n",
    "    # Define adjusted market regimes with offset (shifted by 1 day)\n",
    "    data['Adjusted_Market_Regime'] = data['Market_Regime'].shift(1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def calculate_exposures(data):\n",
    "    # Define initial exposure based on Adjusted_Market_Regime\n",
    "    exposure_mapping = {\n",
    "        'Bullish Low Variance': 2.0,\n",
    "        'Bearish Low Variance': 1.0,\n",
    "        'Bullish High Variance': 1.0,\n",
    "        'Bearish High Variance': 0.0\n",
    "    }\n",
    "    data['Portfolio_Exposure'] = data['Adjusted_Market_Regime'].map(exposure_mapping).fillna(1.0)  # Default exposure is 1.0 if regime is NaN\n",
    "    \n",
    "    # Adjust exposure based on 30-Day and 60-Day Indicators\n",
    "    for index, row in data.iterrows():\n",
    "        if row['Portfolio_Exposure'] == 2.0:\n",
    "            if row['30_Day_Indicator'] == 'Bearish' and row['60_Day_Indicator'] == 'Bearish':\n",
    "                data.at[index, 'Portfolio_Exposure'] = 1.0\n",
    "            elif row['30_Day_Indicator'] == 'Bullish' and row['60_Day_Indicator'] == 'Bearish':\n",
    "                data.at[index, 'Portfolio_Exposure'] = 1.5\n",
    "            elif row['30_Day_Indicator'] == 'Bearish' and row['60_Day_Indicator'] == 'Bullish':\n",
    "                data.at[index, 'Portfolio_Exposure'] = 1.5\n",
    "                    \n",
    "    # Adjust exposure based on 30-Day and 60-Day Indicators for exposure = 1.0 and Bearish Low Variance regime\n",
    "    for index, row in data.iterrows():\n",
    "        if row['Portfolio_Exposure'] == 1.0 and row['Adjusted_Market_Regime'] == 'Bearish Low Variance':\n",
    "            if row['30_Day_Indicator'] == 'Bearish' and row['60_Day_Indicator'] == 'Bearish':\n",
    "                data.at[index, 'Portfolio_Exposure'] = 0.0\n",
    "            elif row['30_Day_Indicator'] == 'Bullish' and row['60_Day_Indicator'] == 'Bearish':\n",
    "                data.at[index, 'Portfolio_Exposure'] = 1.0\n",
    "            elif row['30_Day_Indicator'] == 'Bearish' and row['60_Day_Indicator'] == 'Bullish':\n",
    "                data.at[index, 'Portfolio_Exposure'] = 1.0\n",
    "                    \n",
    "    return data\n",
    "\n",
    "def calculate_returns_and_portfolio_values(data):\n",
    "    initial_value = 100000\n",
    "    \n",
    "    # Initialize 'Beginning_Portfolio_Value' if it does not exist\n",
    "    if 'Beginning_Portfolio_Value' not in data.columns:\n",
    "        data['Beginning_Portfolio_Value'] = initial_value\n",
    "    \n",
    "    # Calculate strategy returns and adjust for leverage cost and transaction costs\n",
    "    data['Leveraged_Portion'] = data['Portfolio_Exposure'] - 1\n",
    "    data['Leveraged_Portion'] = data['Leveraged_Portion'].apply(lambda x: max(x, 0))  # Only positive leverage\n",
    "    \n",
    "    # Adjust leverage cost calculation based on the current portfolio value\n",
    "    data['Leverage_Cost_Amount'] = data['Beginning_Portfolio_Value'] * data['Leveraged_Portion'] * data['Daily_Leverage_Rate']\n",
    "    \n",
    "    # Transaction and Slippage costs calculation\n",
    "    transaction_cost_per_trade = 0.002  # Example: 0.1% per trade + 0.1% per trade on slippage\n",
    "    data['Transaction_Slippage_Costs'] = transaction_cost_per_trade * np.abs(data['Portfolio_Exposure'].diff().fillna(0))\n",
    "    \n",
    "    # Calculate transaction cost in dollar amounts\n",
    "    data['Transaction_Cost_Dollars'] = data['Transaction_Slippage_Costs'] * data['Beginning_Portfolio_Value']\n",
    "    \n",
    "    shorting_cost = 0.003  # Example: 0.3% for shorting\n",
    "    data['Shorting_Costs'] = shorting_cost * (data['Portfolio_Exposure'] < 0).astype(int)\n",
    "    \n",
    "    # Update the strategy return calculation to use leverage cost directly\n",
    "    data['Strategy_Return'] = (\n",
    "        data['Index_Returns'] * data['Portfolio_Exposure']\n",
    "        - data['Leverage_Cost_Amount'] / data['Beginning_Portfolio_Value']  # Use current portfolio value instead of initial\n",
    "        - data['Transaction_Slippage_Costs']\n",
    "        - data['Shorting_Costs']\n",
    "    )\n",
    "    \n",
    "    # Set the strategy return for the first date to 0\n",
    "    data.at[data.index[0], 'Strategy_Return'] = 0\n",
    "    \n",
    "    # Calculate cumulative returns starting with $100,000\n",
    "    data['Portfolio_Value'] = initial_value * (1 + data['Strategy_Return']).cumprod()\n",
    "    data['Market_Value'] = initial_value * (1 + data['Index_Returns']).cumprod()\n",
    "    \n",
    "    # Calculate the beginning portfolio value for each day\n",
    "    data['Beginning_Portfolio_Value'] = data['Portfolio_Value'].shift(1).fillna(initial_value)\n",
    "    \n",
    "    # Recalculate transaction cost in dollar amounts after 'Beginning_Portfolio_Value' is updated\n",
    "    data['Transaction_Cost_Dollars'] = data['Transaction_Slippage_Costs'] * data['Beginning_Portfolio_Value']\n",
    "    \n",
    "    # Calculate the daily return based on the beginning portfolio value\n",
    "    data['Daily_Return'] = data['Beginning_Portfolio_Value'] * data['Strategy_Return']\n",
    "    \n",
    "    # Identify buy/sell signals based on changes in exposure\n",
    "    data['Trade_Signal'] = ''\n",
    "    data['Trade_Signal'] = np.where(data['Portfolio_Exposure'].diff() > 0, 'Buy', data['Trade_Signal'])\n",
    "    data['Trade_Signal'] = np.where(data['Portfolio_Exposure'].diff() < 0, 'Sell', data['Trade_Signal'])\n",
    "    data.at[data.index[0], 'Trade_Signal'] = 'Buy'\n",
    "    \n",
    "    # Adjust trade signals for next day's open price\n",
    "    data['Next_Open'] = data['Open'].shift(0)\n",
    "    data['Trade_Signal_Next_Open'] = data['Trade_Signal'].shift(0)\n",
    "    \n",
    "    # Add new columns to find the Beginning Portfolio Value and Date of the last \"Buy\" signal for each \"Sell\"\n",
    "    data['Last_Buy_Value'] = None\n",
    "    data['Last_Buy_Date'] = None\n",
    "    last_buy_value = None\n",
    "    last_buy_date = None\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if data['Trade_Signal_Next_Open'].iloc[i] == 'Buy':\n",
    "            last_buy_value = data['Next_Open'].iloc[i]\n",
    "            last_buy_date = data.index[i].date()  # Keep only the date element\n",
    "        elif data['Trade_Signal_Next_Open'].iloc[i] == 'Sell' and last_buy_value is not None:\n",
    "            data.at[data.index[i], 'Last_Buy_Value'] = last_buy_value\n",
    "            data.at[data.index[i], 'Last_Buy_Date'] = last_buy_date  # Keep only the date element\n",
    "\n",
    "    # Convert 'Last_Buy_Date' to string format to ensure only date is stored, not time.\n",
    "    data['Last_Buy_Date'] = pd.to_datetime(data['Last_Buy_Date']).dt.date\n",
    "    \n",
    "    # Add a new column for Profit/Loss\n",
    "    def calculate_profit_loss(row):\n",
    "        if (\n",
    "            row['Trade_Signal_Next_Open'] == 'Sell'\n",
    "            and pd.notnull(row['Last_Buy_Value'])\n",
    "            and pd.notnull(row['Next_Open'])\n",
    "        ):\n",
    "            return row['Next_Open'] - row['Last_Buy_Value']\n",
    "        return 0\n",
    "    \n",
    "    data['Profit/Loss'] = data.apply(calculate_profit_loss, axis=1)\n",
    "    \n",
    "    def calculate_tax(row):\n",
    "        if row['Trade_Signal_Next_Open'] == 'Sell' and pd.notnull(row['Last_Buy_Date']):\n",
    "            # Convert Last_Buy_Date to Timestamp to match row.name type\n",
    "            last_buy_date = pd.Timestamp(row['Last_Buy_Date'])\n",
    "            days_held = (row.name - last_buy_date).days\n",
    "            profit_loss = row['Profit/Loss']\n",
    "            if days_held > 365:\n",
    "                return 0.00 * profit_loss\n",
    "            else:\n",
    "                return 0.00 * profit_loss\n",
    "        return 0\n",
    "    \n",
    "    data['Tax'] = data.apply(calculate_tax, axis=1)\n",
    "    \n",
    "    # Calculate Tax Amount in dollars based on the Profit/Loss when selling\n",
    "    data['Tax_Amount'] = data['Tax']\n",
    "    \n",
    "    # Adjust the ending portfolio value for tax when selling\n",
    "    data['Ending_Portfolio_Value'] = np.where(\n",
    "        data['Trade_Signal_Next_Open'] == 'Sell',\n",
    "        data['Beginning_Portfolio_Value'] + data['Daily_Return'] - data['Tax_Amount'],\n",
    "        data['Beginning_Portfolio_Value'] + data['Daily_Return']\n",
    "    )\n",
    "    \n",
    "    # Handle NaN in 'Ending_Portfolio_Value' by filling it with the previous value or the initial value\n",
    "    data['Ending_Portfolio_Value'] = data['Ending_Portfolio_Value'].ffill().fillna(initial_value)\n",
    "    \n",
    "    # Calculate the beginning portfolio value for the next day including tax\n",
    "    data['Beginning_Portfolio_Value'] = data['Ending_Portfolio_Value'].shift(1).fillna(initial_value)\n",
    "    \n",
    "    # Calculate drawdowns for the market (index) and the strategy\n",
    "    data['Index_Drawdown'] = data['Market_Value'] / data['Market_Value'].cummax() - 1\n",
    "    data['Strategy_Drawdown'] = data['Ending_Portfolio_Value'] / data['Ending_Portfolio_Value'].cummax() - 1\n",
    "    \n",
    "    return data\n",
    "\n",
    "def add_triangular_moving_averages_and_indicators(data):\n",
    "    # Calculate 30-day and 60-day Triangular Moving Averages and shift by 1 day\n",
    "    data['30_TMA'] = triangular_moving_average(data['Adj Close'], 4).shift(1)\n",
    "    data['60_TMA'] = triangular_moving_average(data['Adj Close'], 8).shift(1)\n",
    "    \n",
    "    # Define 30-Day and 60-Day Indicators\n",
    "    data['30_Day_Indicator'] = np.where(data['Adj Close'] > data['30_TMA'], 'Bullish', 'Bearish')\n",
    "    data['60_Day_Indicator'] = np.where(data['Adj Close'] > data['60_TMA'], 'Bullish', 'Bearish')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def triangular_moving_average(series, n):\n",
    "    # Calculate the triangular moving average with a two-step rolling mean\n",
    "    smoothed_series = series.rolling(window=(n // 2), min_periods=1).mean()\n",
    "    smoothed_series = smoothed_series.rolling(window=(n // 2), min_periods=1).mean()\n",
    "    return smoothed_series\n",
    "\n",
    "def calculate_custom_metrics(returns):\n",
    "    \"\"\"\n",
    "    Calculate custom performance metrics that are not directly provided by Pyfolio.\n",
    "    \"\"\"\n",
    "    # Annual return\n",
    "    annual_return = ep.annual_return(returns)\n",
    "    \n",
    "    # Cumulative returns\n",
    "    cumulative_returns = ep.cum_returns_final(returns)\n",
    "    \n",
    "    # Annual volatility\n",
    "    annual_volatility = ep.annual_volatility(returns)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe_ratio = ep.sharpe_ratio(returns)\n",
    "    \n",
    "    # Calmar ratio\n",
    "    calmar_ratio = ep.calmar_ratio(returns)\n",
    "    \n",
    "    # Stability\n",
    "    stability = ep.stability_of_timeseries(returns)\n",
    "    \n",
    "    # Max drawdown\n",
    "    max_drawdown = ep.max_drawdown(returns)\n",
    "    \n",
    "    # Omega ratio (using a threshold of 0)\n",
    "    omega_ratio = ep.omega_ratio(returns, required_return=0)\n",
    "    \n",
    "    # Sortino ratio (using a threshold of 0)\n",
    "    sortino_ratio = ep.sortino_ratio(returns, required_return=0)\n",
    "    \n",
    "    # Tail ratio\n",
    "    tail_ratio = ep.tail_ratio(returns)\n",
    "    \n",
    "    # Value at risk (VaR)\n",
    "    var = ep.value_at_risk(returns)\n",
    "    \n",
    "    # Collecting results into a dictionary\n",
    "    metrics = {\n",
    "        'Annual Return': f\"{annual_return:.2%}\",\n",
    "        'Cumulative Returns': f\"{cumulative_returns:.2%}\",\n",
    "        'Annual Volatility': f\"{annual_volatility:.2%}\",\n",
    "        'Sharpe Ratio': f\"{sharpe_ratio:.2f}\",\n",
    "        'Calmar Ratio': f\"{calmar_ratio:.2f}\",\n",
    "        'Stability': f\"{stability:.2f}\",\n",
    "        'Max Drawdown': f\"{max_drawdown:.2%}\",\n",
    "        'Omega Ratio': f\"{omega_ratio:.2f}\",\n",
    "        'Sortino Ratio': f\"{sortino_ratio:.2f}\",\n",
    "        'Tail Ratio': f\"{tail_ratio:.2f}\",\n",
    "        'Value at Risk (VaR)': f\"{var:.2%}\"\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def run_pyfolio_analysis(data):\n",
    "    \"\"\"\n",
    "    Runs a pyfolio tear sheet analysis on the strategy returns and includes custom performance metrics.\n",
    "    \"\"\"\n",
    "    strategy_returns = data['Strategy_Return']\n",
    "    \n",
    "    # Convert index to UTC if not already done\n",
    "    if strategy_returns.index.tz is None:\n",
    "        strategy_returns.index = strategy_returns.index.tz_localize('UTC')\n",
    "    \n",
    "    # Calculate custom metrics\n",
    "    custom_metrics = calculate_custom_metrics(strategy_returns)\n",
    "    \n",
    "    # Create a new PDF file to save plots\n",
    "    pdf_path = 'pyfolio_output_report.pdf'\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        \n",
    "        # Create and save each plot to the PDF as a separate figure\n",
    "        fig, ax = plt.subplots()\n",
    "        pf.plot_rolling_returns(strategy_returns, ax=ax)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        pf.plot_drawdown_underwater(strategy_returns, ax=ax)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        pf.plot_rolling_volatility(strategy_returns, ax=ax)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        pf.plot_rolling_sharpe(strategy_returns, ax=ax)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        pf.plot_monthly_returns_heatmap(strategy_returns, ax=ax)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        pf.plot_annual_returns(strategy_returns, ax=ax)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        pf.plot_monthly_returns_dist(strategy_returns, ax=ax)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Add more plots as needed...\n",
    "    \n",
    "    print(f\"PDF report saved to {pdf_path}\")\n",
    "    \n",
    "    # Display custom metrics\n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    for metric, value in custom_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    \n",
    "    # Create a DataFrame to display in a similar format as in your image\n",
    "    metrics_df = pd.DataFrame(custom_metrics.items(), columns=['Metric', 'Value'])\n",
    "    \n",
    "    print(\"\\nCustom Metrics Table:\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "    \n",
    "    # Save the DataFrame to a CSV file if needed\n",
    "    metrics_df.to_csv('performance_metrics.csv', index=False)\n",
    "\n",
    "def calculate_cagr(portfolio_value):\n",
    "    # Ensure the index is in datetime format\n",
    "    portfolio_value.index = pd.to_datetime(portfolio_value.index)\n",
    "\n",
    "    # Calculate the actual number of years between the first and last date using Decimal\n",
    "    start_date = portfolio_value.index.min()\n",
    "    end_date = portfolio_value.index.max()\n",
    "    total_years = Decimal((end_date - start_date).days) / Decimal(365.25)\n",
    "\n",
    "    # Calculate CAGR using the actual time period with Decimal\n",
    "    start_value = Decimal(portfolio_value.iloc[0])\n",
    "    end_value = Decimal(portfolio_value.iloc[-1])\n",
    "    cagr_value = (end_value / start_value) ** (Decimal(1) / total_years) - Decimal(1)\n",
    "\n",
    "    return float(cagr_value)\n",
    "\n",
    "def calculate_sharpe_ratio(returns, risk_free_rate=0.03, periods_per_year=52):\n",
    "    excess_returns = returns - risk_free_rate / periods_per_year\n",
    "    return np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(periods_per_year)\n",
    "\n",
    "def calculate_sortino_ratio(returns, risk_free_rate=0, periods_per_year=52):\n",
    "    downside_returns = returns[returns < 0]\n",
    "    excess_returns = returns - risk_free_rate / periods_per_year\n",
    "    return np.mean(excess_returns) / np.std(downside_returns) * np.sqrt(periods_per_year)\n",
    "\n",
    "def calculate_information_ratio(strategy_returns, benchmark_returns, periods_per_year=52):\n",
    "    # Ensure both series have the same time zone awareness (UTC for both)\n",
    "    if strategy_returns.index.tz is None:\n",
    "        strategy_returns.index = strategy_returns.index.tz_localize('UTC')\n",
    "    if benchmark_returns.index.tz is None:\n",
    "        benchmark_returns.index = benchmark_returns.index.tz_localize('UTC')\n",
    "\n",
    "    # Align the indices of both returns series to avoid mismatches\n",
    "    strategy_returns, benchmark_returns = strategy_returns.align(benchmark_returns, join='inner')\n",
    "\n",
    "    # Calculate the information ratio\n",
    "    excess_returns = strategy_returns - benchmark_returns\n",
    "    return np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(periods_per_year)\n",
    "\n",
    "def calculate_max_drawdown(portfolio_value):\n",
    "    rolling_max = portfolio_value.cummax()\n",
    "    drawdown = portfolio_value / rolling_max - 1\n",
    "    max_drawdown = drawdown.min()\n",
    "    drawdown_trough_date = drawdown.idxmin()\n",
    "    drawdown_peak_date = rolling_max[:drawdown_trough_date].idxmax()\n",
    "    drawdown_breakeven_date = (portfolio_value[drawdown_trough_date:] >= rolling_max[drawdown_peak_date]).idxmax()\n",
    "    return max_drawdown, drawdown_peak_date, drawdown_trough_date, drawdown_breakeven_date\n",
    "\n",
    "def calculate_performance_metrics(data):\n",
    "    # Calculate strategy and market statistics\n",
    "    strategy_cagr = calculate_cagr(data['Portfolio_Value'])\n",
    "    market_cagr = calculate_cagr(data['Market_Value'])\n",
    "    strategy_max_drawdown, strategy_peak_date, strategy_trough_date, strategy_breakeven_date = calculate_max_drawdown(data['Portfolio_Value'])\n",
    "    market_max_drawdown, _, _, _ = calculate_max_drawdown(data['Market_Value'])\n",
    "    strategy_sharpe_ratio = round(calculate_sharpe_ratio(data['Strategy_Return']), 2)\n",
    "    market_sharpe_ratio = round(calculate_sharpe_ratio(data['Index_Returns']), 2)\n",
    "    strategy_sortino_ratio = round(calculate_sortino_ratio(data['Strategy_Return']), 2)\n",
    "    market_sortino_ratio = round(calculate_sortino_ratio(data['Index_Returns']), 2)\n",
    "    information_ratio = round(calculate_information_ratio(data['Strategy_Return'], data['Index_Returns']), 2)\n",
    "    \n",
    "    # Calculate the percentage of time the Portfolio Exposure is >= 1\n",
    "    exposure_percentage = (data['Portfolio_Exposure'] >= 1).mean() * 100\n",
    "    exposure_percentage_str = f'{exposure_percentage:.2f}%'\n",
    "    \n",
    "    # Format CAGR and Max Drawdown as percentage with 2 decimal places\n",
    "    strategy_cagr_percent = f'{strategy_cagr * 100:.10f}%'\n",
    "    market_cagr_percent = f'{market_cagr * 100:.10f}%'\n",
    "    strategy_max_drawdown_percent = f'{strategy_max_drawdown * 100:.2f}%'\n",
    "    market_max_drawdown_percent = f'{market_max_drawdown * 100:.2f}%'\n",
    "    \n",
    "    # Create the Performance Statistics DataFrame\n",
    "    stats_df = pd.DataFrame({\n",
    "        'Statistic': [\n",
    "            'CAGR',\n",
    "            'Max Drawdown',\n",
    "            'Sharpe Ratio',\n",
    "            'Sortino Ratio',\n",
    "            'Information Ratio',\n",
    "            'Exposure >= 1'\n",
    "        ],\n",
    "        'Strategy': [\n",
    "            strategy_cagr_percent,\n",
    "            strategy_max_drawdown_percent,\n",
    "            strategy_sharpe_ratio,\n",
    "            strategy_sortino_ratio,\n",
    "            information_ratio,\n",
    "            exposure_percentage_str\n",
    "        ],\n",
    "        'Market': [\n",
    "            market_cagr_percent,\n",
    "            market_max_drawdown_percent,\n",
    "            market_sharpe_ratio,\n",
    "            market_sortino_ratio,\n",
    "            np.nan,\n",
    "            np.nan\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "def output_results(data, output_csv_path, output_pdf_path, trades_csv_path, worst_periods_csv_path, stats_df, edited_ticker, start_date, end_date):\n",
    "    # Format the output table after all calculations\n",
    "    formatted_data = data.copy()\n",
    "    \n",
    "    # Display the performance statistics\n",
    "    print(\"\\nPerformance Statistics:\")\n",
    "    print(stats_df.to_string(index=False))\n",
    "    \n",
    "    # Define the desired column order\n",
    "    column_order = [\n",
    "        'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Syn_Open', 'Adjusted_Open',\n",
    "        'FEDFUNDS', 'DGS10', 'TB3MS', 'EFFR', 'Effective_Fed_Rate', 'IBKR_Rate', 'Daily_Leverage_Rate',\n",
    "        'Vol_Regime', '250_TMA', 'Market_Regime', 'Adjusted_Market_Regime', '30_TMA', '60_TMA',\n",
    "        '30_Day_Indicator', '60_Day_Indicator', 'Leveraged_Portion', 'Beginning_Portfolio_Value',\n",
    "        'Index_Returns', 'Portfolio_Exposure', 'Leverage_Cost_Amount', 'Transaction_Slippage_Costs', 'Transaction_Cost_Dollars',\n",
    "        'Shorting_Costs', 'Strategy_Return', 'Daily_Return', 'Trade_Signal', 'Next_Open', 'Trade_Signal_Next_Open',\n",
    "        'Last_Buy_Value', 'Last_Buy_Date', 'Profit/Loss', 'Tax', 'Tax_Amount', 'Ending_Portfolio_Value',\n",
    "        'Index_Drawdown', 'Strategy_Drawdown', 'Portfolio_Value', 'Market_Value'\n",
    "    ]\n",
    "    \n",
    "    # Reorder the columns in the data\n",
    "    data = data[column_order]\n",
    "    \n",
    "    # Save the combined output table to a CSV file\n",
    "    data.to_csv(output_csv_path, index=True)\n",
    "    \n",
    "    # Display the output table in the console\n",
    "    print(\"Output table:\\n\", data)\n",
    "    \n",
    "    # Create the trades output CSV with open and close values and trade signals\n",
    "    trades_data = data[['Open', 'Close', 'Trade_Signal', 'Portfolio_Exposure']].copy()\n",
    "    trades_data['Next_Day_Open'] = trades_data['Open'].shift(-1)\n",
    "    trades_data = trades_data.dropna(subset=['Trade_Signal'])\n",
    "    \n",
    "    # Save the trades data to a CSV file\n",
    "    trades_data.to_csv(trades_csv_path, index=True)\n",
    "    \n",
    "    # Define helper functions\n",
    "    def find_nearest_date(target_date, date_index):\n",
    "        \"\"\"\n",
    "        Find the nearest date in date_index to the target_date\n",
    "        \"\"\"\n",
    "        nearest_date = min(date_index, key=lambda x: abs(x - target_date))\n",
    "        return nearest_date\n",
    "\n",
    "    def plot_3yr_comparisons(data, worst_periods, pdf):\n",
    "        for i, row in worst_periods.iterrows():\n",
    "            start_date = row['Start_Date']\n",
    "            end_date = row['End_Date']\n",
    "            period_data = data.loc[start_date:end_date]\n",
    "    \n",
    "            # Normalize starting values to 100\n",
    "            normalized_strategy = (period_data['Portfolio_Value'] / period_data['Portfolio_Value'].iloc[0]) * 100\n",
    "            normalized_market = (period_data['Market_Value'] / period_data['Market_Value'].iloc[0]) * 100\n",
    "    \n",
    "            fig = plt.figure(figsize=(12, 8))\n",
    "            plt.plot(period_data.index, normalized_strategy, label='Strategy (normalized)')\n",
    "            plt.plot(period_data.index, normalized_market, label='Market Index (normalized)')\n",
    "            plt.title(f'Price Return Comparison from {start_date.date()} to {end_date.date()}')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Normalized Price Return')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            pdf.savefig(fig)\n",
    "            plt.close()\n",
    "    \n",
    "    # Save figures to a PDF report\n",
    "    with PdfPages(output_pdf_path) as pdf:\n",
    "        # Add a cover page\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.axis('off')\n",
    "        cover_title = edited_ticker\n",
    "        end_date_minus_one = pd.to_datetime(end_date) - timedelta(days=1)\n",
    "        cover_date_range = f\"{pd.to_datetime(start_date).strftime('%m/%d/%Y')} - {end_date_minus_one.strftime('%m/%d/%Y')}\"\n",
    "        ax.text(0.5, 0.7, cover_title, fontsize=26, ha='center', va='center', fontname='Times New Roman')\n",
    "        ax.text(0.5, 0.5, cover_date_range, fontsize=16, ha='center', va='center', fontname='Times New Roman')\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    \n",
    "        # Add performance statistics table\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        gs = gridspec.GridSpec(1, 1)\n",
    "    \n",
    "        # Add performance statistics\n",
    "        ax0 = plt.subplot(gs[0])\n",
    "        ax0.axis('tight')\n",
    "        ax0.axis('off')\n",
    "        table = ax0.table(cellText=stats_df.round(6).values,\n",
    "                          colLabels=stats_df.columns,\n",
    "                          cellLoc='center',\n",
    "                          loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1.2, 1.2)\n",
    "        ax0.set_title('Performance Statistics', pad=20)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot the S&P 500 price with regimes highlighted\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "        # Plot each regime segment separately without overlapping\n",
    "        colors = {\n",
    "            'Bearish High Variance': 'red',\n",
    "            'Bullish High Variance': 'green',\n",
    "            'Bearish Low Variance': 'orange',\n",
    "            'Bullish Low Variance': 'blue'\n",
    "        }\n",
    "    \n",
    "        for regime, regime_data in data.groupby((data['Market_Regime'] != data['Market_Regime'].shift()).cumsum()):\n",
    "            regime_label = regime_data['Market_Regime'].iloc[0]\n",
    "            ax.plot(regime_data.index, regime_data['Adj Close'], color=colors.get(regime_label, 'black'), label=regime_label, linewidth=1.35)\n",
    "    \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        unique_labels = dict(zip(labels, handles))\n",
    "        ax.legend(unique_labels.values(), unique_labels.keys())\n",
    "    \n",
    "        ax.set_title('Market Regimes Visualized')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Adjusted Close Price')\n",
    "        ax.grid(True)\n",
    "        ax.set_yscale('log')  # Set y-axis to log scale\n",
    "        years = pd.date_range(start=start_date, end=end_date, freq='5YS' if (pd.to_datetime(end_date).year - pd.to_datetime(start_date).year) > 25 else 'YS').year\n",
    "        ax.set_xticks(pd.to_datetime(years, format='%Y'))\n",
    "        ax.set_xticklabels([f\"'{str(year)[-2:]}\" for year in years])\n",
    "    \n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_rotation(45)\n",
    "            label.set_ha('right')\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    \n",
    "        # Create subplots for final market regimes visualization\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(18, 18), gridspec_kw={'height_ratios': [2, 1, 1]})\n",
    "    \n",
    "        # Plot the S&P 500 price with distinct market regimes highlighted\n",
    "        ax1 = axes[0]\n",
    "        for regime, regime_data in data.groupby((data['Market_Regime'] != data['Market_Regime'].shift()).cumsum()):\n",
    "            regime_label = regime_data['Market_Regime'].iloc[0]\n",
    "            ax1.plot(regime_data.index, regime_data['Adj Close'], color=colors.get(regime_label, 'black'), label=regime_label, linewidth=1.35)\n",
    "    \n",
    "        handles, labels = ax1.get_legend_handles_labels()\n",
    "        unique_labels = dict(zip(labels, handles))\n",
    "        ax1.legend(unique_labels.values(), unique_labels.keys())\n",
    "    \n",
    "        ax1.set_title('Final Market Regimes Visualized')\n",
    "        ax1.set_xlabel('Date')\n",
    "        ax1.set_ylabel('Adjusted Close Price')\n",
    "        ax1.grid(True)\n",
    "        ax1.set_yscale('log')  # Set y-axis to log scale\n",
    "        years = pd.date_range(start=start_date, end=end_date, freq='5YS' if (pd.to_datetime(end_date).year - pd.to_datetime(start_date).year) > 25 else 'YS').year\n",
    "        ax1.set_xticks(pd.to_datetime(years, format='%Y'))\n",
    "        ax1.set_xticklabels([f\"'{str(year)[-2:]}\" for year in years])\n",
    "    \n",
    "        for label in ax1.get_xticklabels():\n",
    "            label.set_rotation(45)\n",
    "            label.set_ha('right')\n",
    "    \n",
    "        # Calculate regime lengths\n",
    "        data.loc[:, 'Regime_Change'] = data['Market_Regime'] != data['Market_Regime'].shift()\n",
    "        data.loc[:, 'Regime_ID'] = data['Regime_Change'].cumsum()\n",
    "        regime_lengths = data.groupby('Regime_ID').size()\n",
    "    \n",
    "        # Calculate descriptive statistics for regime lengths\n",
    "        regime_length_stats = regime_lengths.describe()\n",
    "        print(\"Regime Length Statistics:\\n\", regime_length_stats)\n",
    "    \n",
    "        # Calculate returns statistics for each regime\n",
    "        returns_stats = data.groupby('Market_Regime')['Index_Returns'].agg(['mean', 'std', 'count'])\n",
    "        returns_stats['mean_regime_length'] = regime_lengths.groupby(data['Market_Regime']).mean()\n",
    "    \n",
    "        # Rename columns for clarity\n",
    "        returns_stats.columns = ['Mean Daily Return', 'Daily Standard Deviation', 'Number of Days', 'Mean Regime Length']\n",
    "    \n",
    "        # Convert returns to percentage\n",
    "        returns_stats['Mean Daily Return'] *= 100\n",
    "        returns_stats['Daily Standard Deviation'] *= 100\n",
    "    \n",
    "        print(\"\\nReturns Statistics by Market Regime:\\n\", returns_stats)\n",
    "    \n",
    "        # Plot histogram of regime lengths\n",
    "        ax2 = axes[1]\n",
    "        ax2.hist(regime_lengths, bins=30, edgecolor='black')\n",
    "        ax2.set_title('Histogram of Regime Lengths')\n",
    "        ax2.set_xlabel('Regime Length')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.title.set_position([.5, 1.05])\n",
    "    \n",
    "        # Print returns statistics as a table\n",
    "        ax3 = axes[2]\n",
    "        ax3.axis('tight')\n",
    "        ax3.axis('off')\n",
    "        table = ax3.table(cellText=returns_stats.round(3).values,\n",
    "                          colLabels=returns_stats.columns,\n",
    "                          rowLabels=returns_stats.index,\n",
    "                          cellLoc='center',\n",
    "                          loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(12)\n",
    "        table.scale(1.2, 1.2)\n",
    "        ax3.set_title('Returns Statistics by Market Regime', pad=20)\n",
    "    \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    \n",
    "        # Plot the portfolio value on the first subplot\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "    \n",
    "        ax1 = axes[0]\n",
    "        ax1.plot(data.index, data['Portfolio_Value'], label='Strategy Portfolio', color='blue')\n",
    "        ax1.set_title('Portfolio Value Over Time')\n",
    "        ax1.set_xlabel('Date')\n",
    "        ax1.set_ylabel('Portfolio Value')\n",
    "        ax1.grid(True)\n",
    "        ax1.legend()\n",
    "    \n",
    "        # Plot the market value on the second subplot\n",
    "        ax2 = axes[1]\n",
    "        ax2.plot(data.index, data['Market_Value'], label='Market (S&P 500)', color='black')\n",
    "        ax2.set_title('Market Value Over Time')\n",
    "        ax2.set_xlabel('Date')\n",
    "        ax2.set_ylabel('Market Value')\n",
    "        ax2.grid(True)\n",
    "        ax2.legend()\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    \n",
    "        # Plotting the 3-year comparisons\n",
    "        def rolling_3yr_cagr(series):\n",
    "            window = 252 * 3  # 252 trading days per year\n",
    "            return series.pct_change(window, fill_method=None).apply(lambda x: (1 + x) ** (1 / 3) - 1 if pd.notnull(x) else np.nan)\n",
    "    \n",
    "        data.loc[:, 'Market_3yr_CAGR'] = rolling_3yr_cagr(data['Market_Value'])\n",
    "        data.loc[:, 'Strategy_3yr_CAGR'] = rolling_3yr_cagr(data['Portfolio_Value'])\n",
    "    \n",
    "        def worst_3yr_per_decade(data):\n",
    "            worst_periods = []\n",
    "            for decade in range(1960, 2030, 10):\n",
    "                start_decade = f'{decade}-01-01'\n",
    "                end_decade = f'{decade + 9}-12-31'\n",
    "                decade_data = data.loc[start_decade:end_decade]\n",
    "                if not decade_data.empty:\n",
    "                    worst_period = decade_data.nsmallest(1, 'Market_3yr_CAGR')[['Market_3yr_CAGR', 'Strategy_3yr_CAGR']]\n",
    "                    if not worst_period.empty:\n",
    "                        worst_period['End_Date'] = worst_period.index\n",
    "                        worst_period['Start_Date'] = worst_period['End_Date'] - pd.DateOffset(years=3)\n",
    "                        worst_periods.append(worst_period)\n",
    "            return pd.concat(worst_periods)\n",
    "    \n",
    "        worst_periods_decade = worst_3yr_per_decade(data)\n",
    "        worst_periods_decade['Start_Date'] = worst_periods_decade['Start_Date'].apply(lambda x: find_nearest_date(x, data.index))\n",
    "        worst_periods_decade['End_Date'] = worst_periods_decade['End_Date'].apply(lambda x: find_nearest_date(x, data.index))\n",
    "    \n",
    "        worst_periods_decade['Start_Strategy_Value'] = [data.loc[start, 'Portfolio_Value'] for start in worst_periods_decade['Start_Date']]\n",
    "        worst_periods_decade['End_Strategy_Value'] = [data.loc[end, 'Portfolio_Value'] for end in worst_periods_decade['End_Date']]\n",
    "        worst_periods_decade['Start_Market_Value'] = [data.loc[start, 'Market_Value'] for start in worst_periods_decade['Start_Date']]\n",
    "        worst_periods_decade['End_Market_Value'] = [data.loc[end, 'Market_Value'] for end in worst_periods_decade['End_Date']]\n",
    "    \n",
    "        worst_periods_decade = worst_periods_decade[['Start_Date', 'End_Date', 'Market_3yr_CAGR', 'Strategy_3yr_CAGR',\n",
    "                                                     'Start_Strategy_Value', 'End_Strategy_Value',\n",
    "                                                     'Start_Market_Value', 'End_Market_Value']]\n",
    "    \n",
    "        # Save the worst periods to a CSV file\n",
    "        worst_periods_decade.to_csv(worst_periods_csv_path, index=False)\n",
    "    \n",
    "        # Display the worst periods in the console\n",
    "        print(\"\\nWorst 3-Year Periods for Each Decade (Market Downturns):\")\n",
    "        print(worst_periods_decade)\n",
    "    \n",
    "        # Plotting the 3-year comparisons\n",
    "        plot_3yr_comparisons(data, worst_periods_decade, pdf)\n",
    "    \n",
    "        # Combine current info with the last 30 days exposure and leverage, and market regime\n",
    "        exposure_leverage_30_days = data[['Portfolio_Exposure', 'Leveraged_Portion', 'Market_Regime']].tail(30).reset_index()\n",
    "        exposure_leverage_30_days.columns = ['Date', 'Portfolio Exposure', 'Portfolio Leverage', 'Vol_Regime']\n",
    "        exposure_leverage_30_days['Date'] = exposure_leverage_30_days['Date'].dt.strftime('%m-%d-%Y')\n",
    "    \n",
    "        current_info = {\n",
    "            'Date': ['Current'],\n",
    "            'Portfolio Exposure': [data['Portfolio_Exposure'].iloc[-1]],\n",
    "            'Portfolio Leverage': [data['Leveraged_Portion'].iloc[-1]],\n",
    "            'Vol_Regime': [data['Market_Regime'].iloc[-1]]\n",
    "        }\n",
    "        current_info_df = pd.DataFrame(current_info)\n",
    "    \n",
    "        combined_df = pd.concat([current_info_df, exposure_leverage_30_days], ignore_index=True)\n",
    "    \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.axis('tight')\n",
    "        ax.axis('off')\n",
    "        table = ax.table(cellText=combined_df.values,\n",
    "                         colLabels=combined_df.columns,\n",
    "                         cellLoc='center',\n",
    "                         loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8.5)\n",
    "        table.scale(.90, .90)\n",
    "        ax.set_title('Current Regime, Portfolio Exposure, and Leverage and Market Regime Over the Past 30 Business Days', pad=20)\n",
    "        fig.subplots_adjust(left=0.1, right=0.9)\n",
    "    \n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"\\nPerformance Statistics:\")\n",
    "    print(stats_df.to_string(index=False))\n",
    "    \n",
    "    # Display the combined table in the console\n",
    "    print(\"\\nCombined Table:\")\n",
    "    print(combined_df)\n",
    "    \n",
    "def output_to_database(data):\n",
    "    # Define the desired column order\n",
    "    column_order = [\n",
    "        'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Syn_Open', 'Adjusted_Open',\n",
    "        'FEDFUNDS', 'DGS10', 'TB3MS', 'EFFR', 'Effective_Fed_Rate', 'IBKR_Rate', 'Daily_Leverage_Rate',\n",
    "        'Vol_Regime', '250_TMA', 'Market_Regime', 'Adjusted_Market_Regime', '30_TMA', '60_TMA',\n",
    "        '30_Day_Indicator', '60_Day_Indicator', 'Leveraged_Portion', 'Beginning_Portfolio_Value',\n",
    "        'Index_Returns', 'Portfolio_Exposure', 'Leverage_Cost_Amount', 'Transaction_Slippage_Costs', 'Transaction_Cost_Dollars',\n",
    "        'Shorting_Costs', 'Strategy_Return', 'Daily_Return', 'Trade_Signal', 'Next_Open', 'Trade_Signal_Next_Open',\n",
    "        'Last_Buy_Value', 'Last_Buy_Date', 'Profit/Loss', 'Tax', 'Tax_Amount', 'Ending_Portfolio_Value',\n",
    "        'Index_Drawdown', 'Strategy_Drawdown', 'Portfolio_Value', 'Market_Value'\n",
    "    ]\n",
    "    \n",
    "    # Reorder the columns in the data\n",
    "    data = data[column_order]\n",
    "    \n",
    "    # Reset index to ensure it's a column and not an index\n",
    "    data_reset = data.reset_index()\n",
    "\n",
    "    # Convert all columns of datetime64 dtype to string format\n",
    "    for col in data_reset.select_dtypes(include=['datetime64[ns]', 'datetime64']).columns:\n",
    "        data_reset[col] = data_reset[col].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Convert all 'object' dtype columns containing datetime-like objects to strings\n",
    "    for col in data_reset.select_dtypes(include=['object']).columns:\n",
    "        if isinstance(data_reset[col].iloc[0], (pd.Timestamp, datetime)):\n",
    "            data_reset[col] = data_reset[col].astype(str)\n",
    "\n",
    "    # Iterate through all columns and convert datetime-like objects to strings\n",
    "    for col in data_reset.columns:\n",
    "        data_reset[col] = data_reset[col].apply(lambda x: str(x) if isinstance(x, (pd.Timestamp, datetime)) else x)\n",
    "\n",
    "    # Output to SQLite database\n",
    "    with sqlite3.connect('output/financial_model.db') as conn:\n",
    "        try:\n",
    "            data_reset.to_sql('financial_data', conn, if_exists='replace', index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while writing to the database: {e}\")\n",
    "            print(\"Data types of DataFrame columns:\")\n",
    "            print(data_reset.dtypes)\n",
    "            print(\"First few rows of DataFrame:\")\n",
    "            print(data_reset.head())\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (msm_env)",
   "language": "python",
   "name": "msm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
